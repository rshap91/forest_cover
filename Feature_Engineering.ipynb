{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "import time\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.decomposition import PCA, NMF, TruncatedSVD\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 80\n",
    "pd.options.display.float_format = lambda x : \"{:,.2f}\".format(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15120, 54), (565892, 55))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('clean_data/train.csv', dtype={'Id':str})\n",
    "test = pd.read_csv('clean_data/test.csv', dtype={'Id':str})\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('clean_data/train_cols.json', 'r') as f:\n",
    "    train_cols = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_cols.keys()\n",
    "id_cols = train_cols['id']\n",
    "cat_cols = train_cols['cat_cols']\n",
    "int_cols = train_cols['int_cols']\n",
    "target_col = train_cols['target_col']\n",
    "\n",
    "ftr_cols = int_cols + cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "    - Scale Data\n",
    "    - KMeans and DBSCAN for Cluster Labels as features\n",
    "    - Clustering On PCA/SVD/NMF\n",
    "    - NaiveBayes Probabilities as Features\n",
    "    - Polynomial Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()\n",
    "xtrain_scaled = mm.fit_transform(train[ftr_cols])\n",
    "xtest_scaled = mm.transform(test[ftr_cols])\n",
    "ytrain = train[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "km_train_data = {}\n",
    "km_test_data = {}\n",
    "for k in range(3,15):\n",
    "    print(k)\n",
    "    km = KMeans(k)\n",
    "    km_train = km.fit_predict(xtrain_scaled)\n",
    "    km_test = km.predict(xtest_scaled)\n",
    "    \n",
    "    km_train_data['K'+k] = km_train\n",
    "    km_test_data['K'+k] = km_test\n",
    "    \n",
    "    \n",
    "# make DFS\n",
    "km_train_df = pd.DataFrame(km_train_data)\n",
    "km_test_df = pd.DataFrame(km_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km_train_df.to_csv('clean_data/km_train_df.csv',index=False)\n",
    "km_test_df.to_csv('clean_data/km_test_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPS: 0.1\n",
      "NCLASSES: 3\n",
      "EPS: 0.30000000000000004\n",
      "NCLASSES: 44\n",
      "EPS: 0.5000000000000001\n",
      "NCLASSES: 44\n",
      "EPS: 0.7000000000000001\n",
      "NCLASSES: 45\n",
      "EPS: 0.9000000000000001\n",
      "NCLASSES: 46\n"
     ]
    }
   ],
   "source": [
    "db_train_data = {}\n",
    "db_test_data = {}\n",
    "for eps in [0.1, 0.5, 1, 1.25]:\n",
    "    for ms in range(5,50,10):\n",
    "        print('EPS:',eps, 'MS:', ms )\n",
    "        db = DBSCAN(eps,ms, n_jobs=-1)\n",
    "        db_train = db.fit_predict(xtrain_scaled)\n",
    "        db_test = db.predict(xtest_scaled)\n",
    "        db_train_data['EPS'+eps+'_MS'+ms] = db_train\n",
    "        db_test_data['EPS'+eps+'_MS'+ms] = db_test\n",
    "        \n",
    "# make DFS\n",
    "db_train_df = pd.DataFrame(db_train_data)\n",
    "db_test_df = pd.DataFrame(db_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_train_df.to_csv('clean_data/db_train_df.csv',index=False)\n",
    "db_test_df.to_csv('clean_data/db_test_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD  & PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05662173, 0.        , 0.03061152, ..., 0.        , 0.        ,\n",
       "        0.04504292],\n",
       "       [0.05749436, 0.        , 0.03165892, ..., 0.        , 0.        ,\n",
       "        0.04294279],\n",
       "       [0.03677829, 0.        , 0.16277515, ..., 0.01108842, 0.00330992,\n",
       "        0.07532656],\n",
       "       ...,\n",
       "       [0.02187222, 0.00259417, 0.00087198, ..., 0.0083134 , 0.00683534,\n",
       "        0.00086697],\n",
       "       [0.03059828, 0.00143   , 0.        , ..., 0.00277686, 0.00414615,\n",
       "        0.        ],\n",
       "       [0.03644856, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.00073602]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = svd(n_components = 10)\n",
    "\n",
    "svd_train = svd.fit_transform(xtrain_scaled)\n",
    "svd_test = svd.transform(xtest_scaled)\n",
    "\n",
    "pca = PCA(n_components = 10)\n",
    "\n",
    "pca_train = pca.fit_transform(xtrain_scaled)\n",
    "pca_test = pca.transform(xtest_scaled)\n",
    "\n",
    "\n",
    "# make dataframes\n",
    "svd_train_df = pd.DataFrame(svd_train, columns = ['svd'+str(i) for i in range(svd_train.shape[1])])\n",
    "svd_test_df = pd.DataFrame(svd_test, columns = ['svd'+str(i) for i in range(svd_train.shape[1])])\n",
    "\n",
    "pca_train_df = pd.DataFrame(pca_train, columns = ['pca'+str(i) for i in range(svd_train.shape[1])])\n",
    "pca_test_df = pd.DataFrame(pca_test, columns = ['pca'+str(i) for i in range(svd_train.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd_train_df.to_csv('clean_data/svd_train_df.csv',index=False)\n",
    "svd_test_df.to_csv('clean_data/svd_test_df.csv',index=False)\n",
    "pca_train_df.to_csv('clean_data/pca_train_df.csv',index=False)\n",
    "pca_test_df.to_csv('clean_data/pca_test_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster On Transformed Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km_svd_train_data = {}\n",
    "km_svd_test_data = {}\n",
    "for k in range(3,15):\n",
    "    print(k)\n",
    "    km = KMeans(k)\n",
    "    km_train = km.fit_predict(svd_train)\n",
    "    km_test = km.predict(svd_test)\n",
    "    \n",
    "    km_svd_train_data['SVD_K'+k] = km_train\n",
    "    km_svd_test_data['SVD_K'+k] = km_test\n",
    "    \n",
    "km_pca_train_data = {}\n",
    "km_pca_test_data = {}\n",
    "for k in range(3,15):\n",
    "    print(k)\n",
    "    km = KMeans(k)\n",
    "    km_train = km.fit_predict(pca_train)\n",
    "    km_test = km.predict(pca_test)\n",
    "    \n",
    "    km_pca_train_data['PCA_K'+k] = km_train\n",
    "    km_pca_test_data['PCA_K'+k] = km_test\n",
    "    \n",
    "\n",
    "# Make DFS\n",
    "km_svd_train_df = pd.DataFrame(km_svd_train_data)\n",
    "km_svd_test_df = pd.DataFrame(km_svd_test_data)\n",
    "\n",
    "km_pca_train_df = pd.DataFrame(km_pca_train_data)\n",
    "km_pca_test_df = pd.DataFrame(km_pca_test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km_svd_train_df.to_csv('clean_data/km_svd_train_df.csv',index=False)\n",
    "km_svd_test_df.to_csv('clean_data/km_svd_test_df.csv',index=False)\n",
    "km_pca_train_df.to_csv('clean_data/km_pca_train_df.csv',index=False)\n",
    "km_pca_test_df.to_csv('clean_data/km_pca_test_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_svd_train_data = {}\n",
    "db_svd_test_data = {}\n",
    "for eps in [0.1, 0.5, 1, 1.25]:\n",
    "    for ms in range(5,50,10):\n",
    "        print('EPS:',eps, 'MS:', ms )\n",
    "        db = DBSCAN(eps,ms, n_jobs=-1)\n",
    "        db_train = db.fit_predict(svd_train)\n",
    "        db_test = db.predict(svd_test)\n",
    "        \n",
    "        db_svd_train_data['SVD_EPS'+eps+'_MS'+ms] = db_train\n",
    "        db_svd_test_data['SVD_EPS'+eps+'_MS'+ms] = db_test\n",
    "        \n",
    "db_pca_train_data = {}\n",
    "db_pca_test_data = {}\n",
    "for eps in [0.1, 0.5, 1, 1.25]:\n",
    "    for ms in range(5,50,10):\n",
    "        print('EPS:',eps, 'MS:', ms )\n",
    "        db = DBSCAN(eps,ms, n_jobs=-1)\n",
    "        db_train = db.fit_predict(pca_train)\n",
    "        db_test = db.predict(pca_test)\n",
    "        \n",
    "        db_pca_train_data['PCA_EPS'+eps+'_MS'+ms] = db_train\n",
    "        db_pca_test_data['PCA_EPS'+eps+'_MS'+ms] = db_test\n",
    "        \n",
    "\n",
    "# Make DFS\n",
    "db_svd_train_df = pd.DataFrame(db_svd_train_data)\n",
    "db_svd_test_df = pd.DataFrame(db_svd_test_data)\n",
    "\n",
    "db_pca_train_df = pd.DataFrame(db_pca_train_data)\n",
    "db_pca_test_df = pd.DataFrame(db_pca_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db_svd_train_df.to_csv('clean_data/db_svd_train_df.csv',index=False)\n",
    "db_svd_test_df.to_csv('clean_data/db_svd_test_df.csv',index=False)\n",
    "db_pca_train_df.to_csv('clean_data/db_pca_train_df.csv',index=False)\n",
    "db_pca_test_df.to_csv('clean_data/db_pca_test_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClf():\n",
    "    \"\"\"\n",
    "    Uses Bernoulli NB for Binary Features,\n",
    "    Multinomial NB for integer ftrs,\n",
    "    Gaussian NB for all other ftrs.\n",
    "    \n",
    "    Final Probs is average of 3 predicted probabilities of above models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, bparams={}, mparams={}, gparams={}):\n",
    "        self.bnb = BernoulliNB(**bparams)\n",
    "        self.mnb = MultinomialNB(**mparams)\n",
    "        self.gnb = GaussianNB(**gparams)\n",
    "        \n",
    "        \n",
    "    def get_cols(self, data):\n",
    "        bern_cols = data.columns[data.apply(lambda col: col.nunique() == 2)].tolist()\n",
    "        mult_cols = data.columns[(data.dtypes==int) & ~data.columns.isin(bern_cols)].tolist()\n",
    "        gaus_cols = data.columns[~data.columns.isin(bern_cols+mult_cols)]\n",
    "        assert len(bern_cols) + len(mult_cols) + len(gaus_cols) == data.shape[1]\n",
    "        \n",
    "        self.bern_locs = [data.columns.get_loc(b) for b in bern_cols]\n",
    "        self.mult_locs = [data.columns.get_loc(m) for m in mult_cols]\n",
    "        self.gaus_locs = [data.columns.get_loc(g) for g in gaus_cols]\n",
    "        \n",
    "    \n",
    "    def fit(self, data, target):\n",
    "        self.get_cols(data)\n",
    "        if self.bern_locs:\n",
    "            self.bnb.fit(data.values[:,self.bern_locs], target)\n",
    "        if self.mult_locs:\n",
    "            self.mnb.fit(data.values[:,self.mult_locs], target)\n",
    "        if self.gaus_locs:\n",
    "            self.gnb.fit(data.values[:,self.gaus_locs], target)\n",
    "\n",
    "    \n",
    "    def predict(self, new_data):\n",
    "        all_probs = []\n",
    "        if self.bern_locs:\n",
    "            bprobs = self.bnb.predict_proba(new_data[:,self.bern_locs])\n",
    "            all_probs.append(bprobs)\n",
    "        if self.mult_locs:\n",
    "            mprobs = self.mnb.predict_proba(new_data[:,self.mult_locs])\n",
    "            all_probs.append(mprobs)\n",
    "        if self.gaus_locs:\n",
    "            gprobs = self.gnb.predict_proba(new_data[:,self.gaus_locs])\n",
    "            all_probs.append(gprobs)\n",
    "        all_probs = np.asarray(all_p)\n",
    "        final_probs = all_probs.mean(0)\n",
    "\n",
    "        return final_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>Wilderness_Area1</th>\n",
       "      <th>Wilderness_Area2</th>\n",
       "      <th>Wilderness_Area3</th>\n",
       "      <th>Wilderness_Area4</th>\n",
       "      <th>Soil_Type1</th>\n",
       "      <th>Soil_Type2</th>\n",
       "      <th>Soil_Type3</th>\n",
       "      <th>Soil_Type4</th>\n",
       "      <th>Soil_Type5</th>\n",
       "      <th>Soil_Type6</th>\n",
       "      <th>Soil_Type8</th>\n",
       "      <th>Soil_Type9</th>\n",
       "      <th>Soil_Type10</th>\n",
       "      <th>Soil_Type11</th>\n",
       "      <th>Soil_Type12</th>\n",
       "      <th>Soil_Type13</th>\n",
       "      <th>Soil_Type14</th>\n",
       "      <th>Soil_Type16</th>\n",
       "      <th>Soil_Type17</th>\n",
       "      <th>Soil_Type18</th>\n",
       "      <th>Soil_Type19</th>\n",
       "      <th>Soil_Type20</th>\n",
       "      <th>Soil_Type21</th>\n",
       "      <th>Soil_Type22</th>\n",
       "      <th>Soil_Type23</th>\n",
       "      <th>Soil_Type24</th>\n",
       "      <th>Soil_Type25</th>\n",
       "      <th>Soil_Type26</th>\n",
       "      <th>Soil_Type27</th>\n",
       "      <th>Soil_Type28</th>\n",
       "      <th>Soil_Type29</th>\n",
       "      <th>Soil_Type30</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       0.37    0.14   0.06                              0.19   \n",
       "1       0.37    0.16   0.04                              0.16   \n",
       "2       0.47    0.39   0.17                              0.20   \n",
       "3       0.46    0.43   0.35                              0.18   \n",
       "4       0.37    0.12   0.04                              0.11   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                            0.21                             0.07   \n",
       "1                            0.20                             0.06   \n",
       "2                            0.30                             0.46   \n",
       "3                            0.38                             0.45   \n",
       "4                            0.21                             0.06   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0           0.87            0.86           0.60   \n",
       "1           0.87            0.88           0.61   \n",
       "2           0.92            0.90           0.54   \n",
       "3           0.94            0.90           0.49   \n",
       "4           0.87            0.87           0.60   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  Wilderness_Area1  Wilderness_Area2  \\\n",
       "0                                0.90              1.00              0.00   \n",
       "1                                0.89              1.00              0.00   \n",
       "2                                0.88              1.00              0.00   \n",
       "3                                0.89              1.00              0.00   \n",
       "4                                0.88              1.00              0.00   \n",
       "\n",
       "   Wilderness_Area3  Wilderness_Area4  Soil_Type1  Soil_Type2  Soil_Type3  \\\n",
       "0              0.00              0.00        0.00        0.00        0.00   \n",
       "1              0.00              0.00        0.00        0.00        0.00   \n",
       "2              0.00              0.00        0.00        0.00        0.00   \n",
       "3              0.00              0.00        0.00        0.00        0.00   \n",
       "4              0.00              0.00        0.00        0.00        0.00   \n",
       "\n",
       "   Soil_Type4  Soil_Type5  Soil_Type6  Soil_Type8  Soil_Type9  Soil_Type10  \\\n",
       "0        0.00        0.00        0.00        0.00        0.00         0.00   \n",
       "1        0.00        0.00        0.00        0.00        0.00         0.00   \n",
       "2        0.00        0.00        0.00        0.00        0.00         0.00   \n",
       "3        0.00        0.00        0.00        0.00        0.00         0.00   \n",
       "4        0.00        0.00        0.00        0.00        0.00         0.00   \n",
       "\n",
       "   Soil_Type11  Soil_Type12  Soil_Type13  Soil_Type14  Soil_Type16  \\\n",
       "0         0.00         0.00         0.00         0.00         0.00   \n",
       "1         0.00         0.00         0.00         0.00         0.00   \n",
       "2         0.00         1.00         0.00         0.00         0.00   \n",
       "3         0.00         0.00         0.00         0.00         0.00   \n",
       "4         0.00         0.00         0.00         0.00         0.00   \n",
       "\n",
       "   Soil_Type17  Soil_Type18  Soil_Type19  Soil_Type20  Soil_Type21  \\\n",
       "0         0.00         0.00         0.00         0.00         0.00   \n",
       "1         0.00         0.00         0.00         0.00         0.00   \n",
       "2         0.00         0.00         0.00         0.00         0.00   \n",
       "3         0.00         0.00         0.00         0.00         0.00   \n",
       "4         0.00         0.00         0.00         0.00         0.00   \n",
       "\n",
       "   Soil_Type22  Soil_Type23  Soil_Type24  Soil_Type25  Soil_Type26  \\\n",
       "0         0.00         0.00         0.00         0.00         0.00   \n",
       "1         0.00         0.00         0.00         0.00         0.00   \n",
       "2         0.00         0.00         0.00         0.00         0.00   \n",
       "3         0.00         0.00         0.00         0.00         0.00   \n",
       "4         0.00         0.00         0.00         0.00         0.00   \n",
       "\n",
       "   Soil_Type27  Soil_Type28  Soil_Type29  Soil_Type30  Soil_Type31  \\\n",
       "0         0.00         0.00         1.00         0.00         0.00   \n",
       "1         0.00         0.00         1.00         0.00         0.00   \n",
       "2         0.00         0.00         0.00         0.00         0.00   \n",
       "3         0.00         0.00         0.00         1.00         0.00   \n",
       "4         0.00         0.00         1.00         0.00         0.00   \n",
       "\n",
       "   Soil_Type32  Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  \\\n",
       "0         0.00         0.00         0.00         0.00         0.00   \n",
       "1         0.00         0.00         0.00         0.00         0.00   \n",
       "2         0.00         0.00         0.00         0.00         0.00   \n",
       "3         0.00         0.00         0.00         0.00         0.00   \n",
       "4         0.00         0.00         0.00         0.00         0.00   \n",
       "\n",
       "   Soil_Type37  Soil_Type38  Soil_Type39  Soil_Type40  \n",
       "0         0.00         0.00         0.00         0.00  \n",
       "1         0.00         0.00         0.00         0.00  \n",
       "2         0.00         0.00         0.00         0.00  \n",
       "3         0.00         0.00         0.00         0.00  \n",
       "4         0.00         0.00         0.00         0.00  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_scaled_df = pd.DataFrame(xtrain_scaled, columns = ftr_cols)\n",
    "xtest_scaled_df = pd.DataFrame(xtest_scaled, columns = ftr_cols)\n",
    "xtrain_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbc = NaiveBayesClf()\n",
    "nbc.fit(xtrain_scaled_df, train[target_col])\n",
    "nb_train = nbc.predict(xtrain_scaled_df.values)\n",
    "nb_test = nbc.predict(xtest_scaled_df.values)\n",
    "\n",
    "nb_train_df = pd.DataFrame(nb_train, columns = ['nb_prob_'+str(i) for i in range(nb_probs.shape[1])])\n",
    "nb_test_df = pd.DataFrame(nb_test, columns = ['nb_prob_'+str(i) for i in range(nb_probs.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6579365079365079"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(ytrain.values, probs.argmax(1)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine All New Ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_train_ftrs = [\n",
    "    xtrain_scaled_df,\n",
    "    km_train_df,\n",
    "    db_train_df,\n",
    "    svd_train_df,\n",
    "    pca_train_df,\n",
    "    km_svd_train_df,\n",
    "    km_pca_train_df,\n",
    "    db_svd_train_df,\n",
    "    db_pca_train_df,\n",
    "    nb_train_df\n",
    "]\n",
    "    \n",
    "all_test_ftrs = [ \n",
    "    xtest_scaled_df\n",
    "    km_test_df,\n",
    "    db_test_df,\n",
    "    svd_test_df,\n",
    "    pca_test_df,\n",
    "    km_svd_test_df,\n",
    "    km_pca_test_df,\n",
    "    db_svd_test_df,\n",
    "    db_pca_test_df,\n",
    "    nb_test_df\n",
    "]\n",
    "\n",
    "all_train_df = pd.concat(all_train_ftrs, axis=1)\n",
    "all_test_df = pd.concat(all_test_ftrs, axis=1)\n",
    "\n",
    "all_train_df.shape, all_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_train_df.to_csv('all_train_df.csv', index=False)\n",
    "all_test_df.to_csv('all_test_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
